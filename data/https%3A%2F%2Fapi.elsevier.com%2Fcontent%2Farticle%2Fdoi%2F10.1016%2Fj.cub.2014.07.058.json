{"scopus-eid": "2-s2.0-84908152259", "originalText": "serial JL 272099 291210 291735 291838 291840 291848 31 80 Current Biology CURRENTBIOLOGY 2014-09-22 2014-09-22 2017-10-04T21:34:03 1-s2.0-S096098221400921X S0960-9822(14)00921-X S096098221400921X 10.1016/j.cub.2014.07.058 S300 S300.3 FULL-TEXT 1-s2.0-S0960982214X00187 2017-10-04T17:05:55.975804-04:00 0 0 20140922 2014 2014-09-22T16:30:38.799751Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body acknowledge affil articletitle auth authfirstini authfull authlast primabst pubtype ref teaserabst 0960-9822 09609822 true 24 24 18 18 Volume 24, Issue 18 22 R910 R920 R910 R920 20140922 22 September 2014 2014-09-22 2014 Applied Neuroscience Special Issue Reviews article rev Copyright \u00a9 2014 Elsevier Ltd. All rights reserved. ROBOTICSNEUROSCIENCE FLOREANO D Main Text Introduction Invertebrates Perception Locomotion Navigation Vertebrates Locomotion Sensorimotor Coordination Navigation Primates Early Influence of Robotics on Primate Neuroscience Model-Based Control Movement Planning and Imitation Locomotion Conclusions Acknowledgments References FREEMAN 2001 W BIOGRAPHICALESSAYWGREYWALTER WALTER 1950 42 45 W BRAITENBERG 1986 V VEHICLESEXPERIMENTSINSYNTHETICPSYCHOLOGY CHIEL 1997 553 557 H NISHIKAWA 2007 16 54 K WEBB 2002 359 363 B WEBB 2000 247 269 B GRASSO 2000 115 131 F PYK 2006 197 213 P FLOREANO 2009 D FLYINGINSECTSROBOTS HORRIDGE 1992 271 282 G BORST 2002 419 437 A KOENDERINK 1986 161 179 J WAGNER 1986 527 551 H FRANCESCHINI 1992 283 294 N SRINIVASAN 2011 389 411 M FRANCESCHINI 2007 329 335 N ZUFFEREY 2007 1671 1684 J BEYELER 2009 201 219 A HUMBERT 2010 63 71 J FLYINGINSECTSROBOTS WIDEFIELDINTEGRATIONMETHODSFORVISUOMOTORCONTROL SONG 2013 95 99 Y FLOREANO 2013 9267 9272 D FULLER 2014 20140281 S DALTORIO 2013 035003 K MA 2013 603 607 K HU 2003 663 666 D SONG 2007 578 589 Y IZQUIERDO 2013 e1002890 E BEER 1992 356 365 R IJSPEERT 2008 642 653 A CRUSE 1990 15 21 H AYERS 2007 273 295 J SPAGNA 2007 9 J ZEIL 2010 87 100 J FLYINGINSECTSROBOTS VISUALHOMINGININSECTSROBOTS CARTWRIGHT 1983 521 543 B ANDERSON 1977 335 355 A LAMBRINOS 2000 39 64 D MOLLER 2000 231 243 R MOLLER 2009 87 101 R FRANZ 1998 111 125 M ZEIL 2003 450 469 J GRILLNER 2013 5425 5431 S GRILLNER 1995 270 279 S WILBUR 2002 C ALAMPREYBASEDUNDULATORYVEHICLE MANFREDI 2013 513 527 L EKEBERG 1993 363 374 O IJSPEERT 2007 1416 1420 A CABELGUEN 2003 2434 2439 J KIMURA 2001 859 878 H KIMURA 2007 475 490 H PEARSON 2004 123 129 K OWAKI 2013 20120669 D MACIVER 2004 651 659 M PEARSON 2007 223 240 M HELD 1963 872 R SUZUKI 2005 656 665 M NEVELN 2013 2501 2514 I SOLBERG 2008 529 548 J BOYER 2012 492 505 F PRESCOT 2009 T SCHROEDER 2012 C OKEEFE 1996 425 428 J TOURETZKY 1994 57 68 D BURGESS 1997 1535 1543 N OKEEFE 1979 419 439 J FLEISCHER 2007 3556 3561 J MARR 1982 D VISIONACOMPUTATIONALINVESTIGATIONHUMANREPRESENTATIONPROCESSINGVISUALINFORMATION HILDRETH 1985 E COMPUTATIONALAPPROACHVISIONMOTORCONTROL MARR 1968 437 470 D ALBUS 1975 228 233 J ITO 1982 275 296 M HOGAN 1984 681 690 N FLASH 1985 1688 1703 T SLOTINE 1991 J APPLIEDNONLINEARCONTROL LATASH 1993 M CONTROLHUMANMOVEMENT GOMI 1996 117 220 H WOLPERT 1998 338 347 D KAWATO 1999 718 727 M AN 1987 C MODELBASEDCONTROLAROBOTMANIPULATOR KAWATO 1990 365 372 M ADVANCESINNEURALCOMPUTATION FEEDBACKERRORLEARNINGNEURALNETWORKFORSUPERVISEDMOTORLEARNING SHIBATA 2001 201 216 T NAKANISHI 2004 1453 1465 J GROSSBERG 1989 S NEURALDYNAMICSADAPTIVESENSORYMOTORCONTROL IMAMIZU 2003 5461 5466 H GOMI 1993 485 497 H ATKESON 1997 75 113 C SCHAAL 1994 57 71 S SCHAAL 1998 2047 2084 S VIJAYAKUMAR 2005 2602 2634 S MEHTA 2002 942 953 B MORASSO 1981 223 227 P MORASSO 1983 187 194 P STEIN 1986 131 150 R HUMANMUSCLEPOWER OPTIMIZEDINMUSCULARMOVEMENTS TODOROV 2004 907 915 E SHADMEHR 2005 R COMPUTATIONALNEUROBIOLOGYREACHINGPOINTINGAFOUNDATIONFORMOTORLEARNING SCOTT 2004 532 546 S TODOROV 2009 11478 11483 E THEODOROU 2010 3137 3181 E STULP 2012 F SCHAAL 1999 233 242 S IJSPEERT 2013 328 373 A STERNAD 1999 118 136 D SCHAAL 2001 60 72 S BULLOCK 1988 49 90 D SCHAAL 2007 425 445 S SCHAAL 2004 1137 1144 S BILLARD 2008 A HANDBOOKROBOTICS ROBOTPROGRAMMINGBYDEMONSTRATION PASTOR 2013 351 361 P RIZZOLATTI 1996 131 141 G RIZZOLATTI 1998 188 194 G OZTOP 2006 254 271 E DEMIRIS 2006 361 369 Y BILLARD 2006 251 253 A BURDET 2013 E HUMANROBOTICS TAGA 1991 147 159 G TAGA 1998 9 17 G ENDO 2008 213 228 G MATSUBARA 2006 911 920 T AOI 2005 219 232 S GENG 2006 1156 1196 T GENG 2006 243 259 T COLLINS 2005 1082 1085 S HODGINS 1989 249 252 J RAIBERT 1986 M LEGGEDROBOTSBALANCE KAJITA 2008 S HANDBOOKROBOTICS LEGGEDROBOTS KAJITA 2008 S HANDBOOKROBOTICS LEGGEDROBOTS KOOLEN 2012 1094 1113 T FULL 1999 3325 3332 R FLOREANOX2014XR910 FLOREANOX2014XR910XR920 FLOREANOX2014XR910XD FLOREANOX2014XR910XR920XD Full 2015-09-22T00:04:04Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window item S0960-9822(14)00921-X S096098221400921X 1-s2.0-S096098221400921X 10.1016/j.cub.2014.07.058 272099 2017-10-04T17:05:55.975804-04:00 2014-09-22 1-s2.0-S096098221400921X-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/MAIN/application/pdf/bd343ae663f5ce71e4a753613acf40b2/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/MAIN/application/pdf/bd343ae663f5ce71e4a753613acf40b2/main.pdf main.pdf pdf true 2007200 MAIN 11 1-s2.0-S096098221400921X-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/PREVIEW/image/png/297720f1df4e9f42522d35eb92d39b2f/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/PREVIEW/image/png/297720f1df4e9f42522d35eb92d39b2f/main_1.png main_1.png png 110279 849 656 IMAGE-WEB-PDF 1 1-s2.0-S096098221400921X-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr1/THUMBNAIL/image/gif/2fea2d7abd766d18a97910a0cf437e2b/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr1/THUMBNAIL/image/gif/2fea2d7abd766d18a97910a0cf437e2b/gr1.sml gr1 gr1.sml sml 22187 163 119 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr2/THUMBNAIL/image/gif/18970d1a1a1a00dd1fd786d1e46e801a/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr2/THUMBNAIL/image/gif/18970d1a1a1a00dd1fd786d1e46e801a/gr2.sml gr2 gr2.sml sml 19073 135 219 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr3/THUMBNAIL/image/gif/eb8ef41f4beb1e588245fb23cab7e2cc/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr3/THUMBNAIL/image/gif/eb8ef41f4beb1e588245fb23cab7e2cc/gr3.sml gr3 gr3.sml sml 22435 138 219 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr4/THUMBNAIL/image/gif/ea108ed4a0b7d2d1aaa831a58e597a2a/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr4/THUMBNAIL/image/gif/ea108ed4a0b7d2d1aaa831a58e597a2a/gr4.sml gr4 gr4.sml sml 25222 135 219 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr5/THUMBNAIL/image/gif/6e5f41cb3d5d847c22fad958ad053e34/gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr5/THUMBNAIL/image/gif/6e5f41cb3d5d847c22fad958ad053e34/gr5.sml gr5 gr5.sml sml 23160 164 108 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr6/THUMBNAIL/image/gif/04902641862cee98ec47f0f82c2a27a5/gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr6/THUMBNAIL/image/gif/04902641862cee98ec47f0f82c2a27a5/gr6.sml gr6 gr6.sml sml 25635 113 219 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr7/THUMBNAIL/image/gif/2002f41f9feb75c4b59fe3e413a7a472/gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr7/THUMBNAIL/image/gif/2002f41f9feb75c4b59fe3e413a7a472/gr7.sml gr7 gr7.sml sml 19716 164 90 IMAGE-THUMBNAIL 1-s2.0-S096098221400921X-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr1/DOWNSAMPLED/image/jpeg/34b964162f2810e60f872261e8e89dc2/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr1/DOWNSAMPLED/image/jpeg/34b964162f2810e60f872261e8e89dc2/gr1.jpg gr1 gr1.jpg jpg 61148 516 376 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr2/DOWNSAMPLED/image/jpeg/40a4416242e9cb3b2fb08a07a8c7e364/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr2/DOWNSAMPLED/image/jpeg/40a4416242e9cb3b2fb08a07a8c7e364/gr2.jpg gr2 gr2.jpg jpg 21854 232 376 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr3/DOWNSAMPLED/image/jpeg/22c8e59bb4a5a7032f00e673f83db341/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr3/DOWNSAMPLED/image/jpeg/22c8e59bb4a5a7032f00e673f83db341/gr3.jpg gr3 gr3.jpg jpg 50799 319 505 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr4/DOWNSAMPLED/image/jpeg/02459205ae8e95f6b0981ddacd0ea4b6/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr4/DOWNSAMPLED/image/jpeg/02459205ae8e95f6b0981ddacd0ea4b6/gr4.jpg gr4 gr4.jpg jpg 62867 311 505 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr5/DOWNSAMPLED/image/jpeg/189a89bfbbf495171bc209a884793f34/gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr5/DOWNSAMPLED/image/jpeg/189a89bfbbf495171bc209a884793f34/gr5.jpg gr5 gr5.jpg jpg 83058 572 376 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr6/DOWNSAMPLED/image/jpeg/a7fa9d40255e196d31b09062566ad44e/gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr6/DOWNSAMPLED/image/jpeg/a7fa9d40255e196d31b09062566ad44e/gr6.jpg gr6 gr6.jpg jpg 46192 261 506 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr7/DOWNSAMPLED/image/jpeg/924c769f8f3b366b232fc6849f015908/gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr7/DOWNSAMPLED/image/jpeg/924c769f8f3b366b232fc6849f015908/gr7.jpg gr7 gr7.jpg jpg 73550 683 375 IMAGE-DOWNSAMPLED 1-s2.0-S096098221400921X-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr1/HIGHRES/image/jpeg/a004bb93a4f8daa01454a868c88eee26/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr1/HIGHRES/image/jpeg/a004bb93a4f8daa01454a868c88eee26/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 356584 2288 1666 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr2/HIGHRES/image/jpeg/659762d03111a0faa32b5e1c73d4a312/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr2/HIGHRES/image/jpeg/659762d03111a0faa32b5e1c73d4a312/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 144323 1028 1666 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr3/HIGHRES/image/jpeg/90a4c728287f576d7678b37159a4bfc0/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr3/HIGHRES/image/jpeg/90a4c728287f576d7678b37159a4bfc0/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 264828 1413 2238 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr4/HIGHRES/image/jpeg/b803d6bcdce4a890bf9aaae01115d511/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr4/HIGHRES/image/jpeg/b803d6bcdce4a890bf9aaae01115d511/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 426133 1379 2237 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr5/HIGHRES/image/jpeg/6ced024fe93871118c7f268271e792e3/gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr5/HIGHRES/image/jpeg/6ced024fe93871118c7f268271e792e3/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 742861 2533 1666 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr6/HIGHRES/image/jpeg/53a8f2ca2108b870dd1437e004bb8d40/gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr6/HIGHRES/image/jpeg/53a8f2ca2108b870dd1437e004bb8d40/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 275653 1155 2241 IMAGE-HIGH-RES 1-s2.0-S096098221400921X-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S096098221400921X/gr7/HIGHRES/image/jpeg/0d3adc220aade1c6648efdd889f56fa4/gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S096098221400921X/gr7/HIGHRES/image/jpeg/0d3adc220aade1c6648efdd889f56fa4/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 457102 3023 1660 IMAGE-HIGH-RES CURBIO 11349 S0960-9822(14)00921-X 10.1016/j.cub.2014.07.058 Elsevier Ltd Figure 1 Drones with insect-like vision. (A) An indoor vision-based drone developed by Zufferey et al. [19] at EPFL is equipped with linear camera facing forward (d), linear camera facing downward (c), propeller (a), anemometer (e), rudder and ailerons (b), and battery (f). (B) An outdoor vision-based drone developed by Beyeler et al. [20] at EPFL is equipped with seven optic flow sensors pointing left, left-down, down, right-down, and right. (Reproduced from [20] with kind permission from Springer Science and Business Media.) Figure 2 Curved artificial compound eye. Developed by a European team lead by Dario Floreano [23], the cylindrical array of 670 neuromorphic ommatidia are glued on a green scaffold enclosing electronics capable of extracting optic flow at 300 Hz with neurally plausible algorithms. Figure 3 A lamprey-like swimming robot. The robot was constructed by Manfredi et al. [49] to explore the mechanisms of visually-guided swimming in the lamprey. (Reproduced from [49] with kind permission from Springer Science and Business Media.) Figure 4 A salamander robot driven by a spinal cord model. (A) Numerical model of the salamander central pattern generator for swimming and walking. (B) An amphibious salamander robot [51]. The CPG and robot could replicate the typical swimming and walking gaits of the salamander, and induce a gait transition between the two depending on the level of stimulation coming from the simulated mesencephalic locomotor region (MLR). Figure 5 Robots equipped with whiskers. (A) Whiskerbot. (Reproduced from [58] by permission of SAGE.) (B) Scratchbot (courtesy of Bristol Robotics Laboratory [58]). The robots are equipped with differential wheels for navigation, and with an articulated head and active whiskers. They were used to explore the neural mechanisms underlying active whiskering. Figure 6 Anthropomorphic torque-controlled robots. These robots were developed for computational neuroscience in a collaboration between the ATR Computational Neuroscience Labs (Japan), Sarcos Inc. (Salt-Lake City, Utah), the University of Southern California (Los Angeles, CA), and Carnegie Mellon University (Pittsburgh, PA). (A) A Sarcos Dexterous Arm robot that was used in various behavioural experiments for neuroscientific studies. (B) The Sarcos Humanoid DB, used for internal model learning experiments. (C) A Sarcos Humanoid, used for locomotion experiments. Figure 7 Research on movement primitives. (A) Dual arm (Barrett Inc.) robotic test bed to study manipulation with (dynamic) motor primitives. (B) Results of fMRI study on distinguishing rhythmic and discrete movement primitives in the human brain (blue areas are primarily involved in discrete movements, green areas are primarily involved in rhythmic movement). Review Robotics and Neuroscience Dario Floreano 1 \u2217 Dario.Floreano@epfl.ch Auke Jan Ijspeert 2 Stefan Schaal 3 1 Laboratory of Intelligent Systems, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Station 11, Lausanne, CH 1015, Switzerland 2 Biorobotics Laboratory, Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Station 14, Lausanne, CH 1015, Switzerland 3 Max-Planck-Institute for Intelligent Systems, Spemannstrasse 41, 72076 T\u00fcbingen, Germany, & University of Southern California, Ronald Tutor Hall RTH 401, 3710 S. McClintock Avenue, Los Angeles, CA 90089-2905, USA \u2217 Corresponding author In the attempt to build adaptive and intelligent machines, roboticists have looked at neuroscience for more than half a century as a source of inspiration for perception and control. More recently, neuroscientists have resorted to robots for testing hypotheses and validating models of biological nervous systems. Here, we give an overview of the work at the intersection of robotics and neuroscience and highlight the most promising approaches and areas where interactions between the two fields have generated significant new insights. We articulate the work in three sections, invertebrate, vertebrate and primate neuroscience. We argue that robots generate valuable insight into the function of nervous systems, which is intimately linked to behaviour and embodiment, and that brain-inspired algorithms and devices give robots life-like capabilities. In their review, Floreano et al showcase instances where robotics and neuroscience have fruitfully interacted and yielded mutual new insights. Main Text Introduction Intelligent robots are behavioural agents that autonomously interact with their environment through sensors, actuators, and a control system producing motor actions from sensory data. Interestingly, what is today considered the first autonomous robot [1] was built in the early 1950s by neurophysiologist William Grey Walter [2], to show that complex, purpose-driven behaviours can be produced by few interconnected neuron-like analog electronic devices that close the loop between perception and action in a situated and embodied system (see, https://www.youtube.com/watch?v=lLULRlmXkKo). Along this line of thought, thirty years later the neuroanatomist Valentino Braitenberg [3] conceived a series of imaginary vehicles with simple sensors and wirings inspired by universal properties of nervous systems and argued that the resulting behavioural complexity originated from the interaction with the environment rather than from the complexity of the brain, and that traditional analysis of nervous systems can learn from the \u2018synthesis\u2019 (construction) of behavioural systems. Indeed, nervous systems cannot be understood in isolation from body and behaviour, because physical properties (mass, springs, temporal delays, friction, etc.) significantly alter the behavioural effects of neural signals and affect the co-evolution and co-development of brains and bodies [4]. Consequently, it has been argued that understanding brains requires the joint analysis and synthesis of relevant parts of the body, environment and neural systems [5]. Understanding motor control requires understanding a series of specific transformations from neural signals to musculoskeletal systems to the environment where the complexity of animal bodies may simplify, instead of complicating, control [6]. In this context, robots incorporating the biomechanics of the animal system under study become physical models to test hypotheses. In the following sections we will examine to what extent neuroscience and robotics have resulted in novel insights and devices in the specific fields of invertebrates, vertebrates, and primates. Invertebrates Invertebrates produce more stereotyped behaviours and are easier to manipulate than most vertebrates, making them suitable candidates for embodiment of neuronal models in robots [7]. Perception Insect behaviour largely depends on external stimulation of the perceptual apparatus, which triggers basic reactions such as attraction and evasion. Mobile robots have been often used to understand the neural underpinnings of taxis, movement towards or away from a stimulus source. For example, Webb and Scutt [8] resorted to a mobile robot equipped with a bio-mimetic bilateral acoustic apparatus to disambiguate between two different neuronal models of cricket phonotaxis whereby females can discriminate and approach conspecific males that produce species-specific songs. The authors showed that two spiking neurons replicating the temporal coding properties of identified auditory neurons were sufficient to reproduce a large variety of phonotactic behaviours observed in real crickets, supporting the hypothesis that recognition and localization of a singing cricket does not require two separate neuronal mechanisms. Chemotactic behaviour of invertebrates has been studied in a variety of contexts. For example, Grasso et al. [9] used an underwater robot to test and discriminate between different neuroethological hypotheses of how lobsters detect and navigate towards the source of a chemical plume in turbulent water. The robot was designed to accurately model the dimension of the lobster and its chemical sensor layout, while the locomotion system was abstracted as a pair of wheels. Similarly, Pyk et al. [10] used wheeled and flying robots equipped with bio-mimetic chemical sensors to falsify a neuronal hypothesis of moth chemotactic behaviour and propose an alternative hypothesis. Robots have also been used to investigate the neural mechanisms that allow flying insects to navigate in complex environments with a compound eye radically different from vertebrate eyes, featuring coarse spatial resolution, fixed focus, and almost complete lack of stereovision. Models of those neural mechanisms have also led to the development of vision-based control of robot drones flying near the ground or in cluttered environments [11]. Insects rely on image motion generated by their own movement to avoid obstacles, regulate speed and latitude, chase, escape and land [12,13]. There is a mathematical correspondence between the amplitude of image motion, also known as optic flow, and the distance to corresponding objects when the viewer translates on a straight line, but not when it rotates [14]. It has been speculated that freely flying flies follow straight lines interrupted by rapid turns, during which visual signals are suppressed, in order to estimate distances using translational optic flow [15]. This hypothesis was tested by Franceschini, Pichon, Blan\u00e8s and Brady [16], using a wheeled robot equipped with a circular array of compound eyes, whose analog electronics mimicked the elementary motion detection circuitry of visual neurons. This robot could perform collision-free navigation in a cluttered environment by moving along straight lines interrupted by sharp avoidance rotations during which visual information was ignored. In another study, Srinivasan et al. [17] argued that, as the angular velocity of the image projected on the ventral side of the insect is proportional to the ratio between horizontal speed and height, insects regulate their speed by maintaining a constant image motion, which results in graceful deceleration during landing. The hypothesis that a simple mechanism of optic flow regulation could be used to control altitude and landing without explicitly measuring distance to the ground was validated with helicopters equipped with two artificial ommatidia pointing towards the ground. The same optic flow regulator was then shown to be effective to reproduce a variety of other behaviours observed in insects, such as terrain following and corridor centering [18]. It has also been shown that optic flow regulation of collision-free navigation and altitude control in indoor [19] and outdoor [20] free-flying drones (Figure 1 ) can be achieved by making roll and pitch angles dependent on two weighted sums of optic flow intensities \u2014 a simple operation that could be accomplished by wide-field visual neurons in the lobula plata complex of the insect brain. Indeed, Humbert et al. [21] proposed the hypothesis that wide-field tangential cells in the visual system of insects are not used to estimate self-motion, as previously argued, but to detect discrepancies between desired and observed optic flow, and use these discrepancies to correct navigation in a feedback loop. The authors successfully tested this hypothesis on a micro-helicopter using analog very large-scale integration (VLSI) sensors and models of the tangential neurons flying in textured environments. Insect compound eyes have also inspired the development of novel types of tiny cameras capable of unparalleled fields of view with no angular distortion. Recently, two different designs of miniature artificial compound eyes have been proposed. Song et al. [22] described an hemispherical compound eye combining elastomeric compound optics with deformable arrays of thin silicon photodetectors that could be shaped into a half sphere to grab wide-field images. Floreano et al. [23] instead described a semi-cylindrical compound eye made of a layer of compound optics, a layer of neuromorphic photodetectors with self-adjusting light sensitivity and a layer of signal processing electronics (Figure 2 ) that can extract optic flow even faster than the insect. A compound eye composed of three ocelli has been added to an insect-size flying robot to validate the hypothesis that some insects may use visual information, instead of angular accelerations, to stabilize flight [24]. Locomotion The large variety of locomotion strategies observed in insects inspired several types of locomotion systems in robots, such as peristalsis, jumping, flying and walking on water [25\u201329], to mention a few. However, most of the research in this area still focuses on the mechanical aspects of the locomotion system, and relatively few authors have ventured into neurally inspired control of these robots. Izquierdo and Beer [30] investigated a neuronal circuit derived from neuroanatomical constraints of the Caenorhabditis elegans connectome in a simulated worm body and environment, and used artificial evolution to predict unknown electrophysiological parameters of the nervous system necessary to generate worm-like movements of klinotaxis. Evolved individuals revealed consistent neurophysiological and behavioural patterns, which prompted the authors to suggest a series of new experiments, such as a better study of turning as a function of gradient and ablation of specific neurons. Some hexapod robots have been developed to understand sensory-motor control of legged invertebrates and address, for instance, questions of how rhythms are generated either by central pattern generators [31], i.e. systems of coupled neural oscillators that have been found in many invertebrates [32], or by chains of reflexes [33]. These robots range from robots with legs that have only two degrees of freedom to validate theories of basic gait control [31,33], to robots with legs that capture biomechanical properties of real cockroaches [34], all the way to robots with legs equipped with pneumatic artificial muscles that could be directly driven by electrical activity of the neuromuscular system of the insect [35]. Interestingly, each robot was designed to address a specific question raised by discrepancies between the insect and the previous version of the robot [6], revealing the usefulness of robots in generating new insights into the functioning of the nervous system. Ayers et al. [36] developed a bio-mimetic lobster robot whose legs were activated by artificial muscles that produced movements similar to those of the animal and used it to propose hypotheses of neuronal control for which neuroscience data are not available. In another study, Spagna et al. [37] argued that insects required to rapidly walk over irregular terrain rely on distributed mechanical feedback to stabilize rather than on neuronal feedback (which does not have sufficient bandwidth) and showed that ghost crabs equipped with prosthetic and compliant spines on their legs could actually improve their natural walking abilities. In order to further corroborate the hypothesis that neural control does not play a role in those situations, they modified the legs of an hexapod robot, but not its control system, to approximate the biomechanics of the modified crab legs and found that the robot improved its walking capabilities. Navigation Robots have also been used to study higher \u2018cognitive capabilities\u2019 of invertebrates, such as spatial memory [38]. Several insects can find their nest or foraging area after traveling for hundreds of meters or long periods of time. The widely accepted \u2018snapshot model\u2019 [39] assumes that insects compute the homing direction by comparing the retinal positions of landmarks in orientation-adjusted snapshots of their visual surrounding taken at different intervals. However, this model requires the nervous system to engage in intensive computation and cannot explain experimental results where portions of the landmarks were removed between outgoing and return flights of insects [40]. A more parsimonious version of the snapshot model, named the \u2018average landmark vector (ALV) model\u2019, was recently proposed and tested with mobile robots [41]. This model assumes that the insect represents each visual landmark as a unit vector and that all landmark vectors detected at a position are averaged to produce an ALV. The insect memorizes only the target ALV and during the return path continuously generates a new homing vector by computing the difference between the currently perceived ALV and the memorized target ALV. As in the snapshot model, the current ALV must be aligned to the target ALV by means of a compass before computing the home vector. When tested in a variety of simulated and real robots, including implementations in neural inspired analog electronics [42,43], the ALV model produced trajectories that are comparable (although not identical) to the original snapshot model and also replicated behavioural patterns that the original snapshot model could not explain. Other authors have suggested that instead of an ALV the environment can be represented as a connected graph where nodes are panoramic snapshots taken at specific locations and edges are motor commands that lead the insect or robot to other connected locations by means of path integration [44]. An alternative hypothesis based on image statistics collected by a mobile robot suggests that insects may memorize a snapshot of the target location and chose movements in the direction that minimizes the root mean square error between the current image and the image taken at the target location, which has been shown to be a monotonically decreasing function of distance from the target [45]. Vertebrates Vertebrates possess some unique learning abilities and rich motor skills that have attracted the attention of neuroscientists and roboticists alike. Locomotion Similarly to invertebrates, vertebrates have conquered multiple ecological niches. From fish to mammals, they exhibit multiple types of morphology and different modes of locomotion in water, on ground and in the air. Interestingly, despite the large variation of morphology, the organization of the underlying motor control systems is quite well conserved [46]. Similarly to the ganglions of invertebrates, the spinal cord contains oscillatory circuits called central pattern generators (CPGs) that can generate complex periodic motor patterns while being activated and modulated by relatively simple descending drive signals. The lamprey is probably one of the vertebrates whose spinal locomotor circuit is best known [47]. Because of its relatively simple eel-like shape it has also served as inspiration for the construction of swimming robots [48,49]. The lamprey swims using an anguilliform swimming gait in which a lateral undulation of increasing amplitude is propagated from head to tail. The underlying CPG is composed of multiple coupled oscillatory networks distributed along the spinal cord. The coupling between the CPG circuits, the body, and the environment have first been studied with neuromechanical simulations [50], then with real robots [48,49]. Wilbur and colleagues [48] built a lamprey-like robot actuated with five pairs of artificial muscles made of shape-memory alloys (Figure 3 ). They carefully analysed different motor behaviours exhibited by freely moving lamprey such as forward swimming, burrowing, crawling, turning and withdrawal. Based on those analyses, they constructed a CPG as a look-up table that could replay similar activation patterns of the artificial muscles. The robot could successfully swim forward, turn and burrow. Another lamprey robot with an original actuation system based on permanent magnets was constructed to test hypotheses about visually-guided goal-directed behaviour [49], specifically how head stabilization (obtained by generating neck movements in opposite phase to those of the trunk) affected tracking performance of a moving target. Two swimming strategies were compared, with and without head stabilization, and it was found that using head stabilization largely improved keeping track of the target with only a small decrease of swimming speed. The authors also observed that the CPG patterns resulted in lamprey-like swimming and could generate sharp turning resembling that of a real lamprey. Salamanders use an anguilliform swimming gait like lampreys, and a walking trot gait also observed in lizards. Ijspeert and colleagues [51] developed an amphibious salamander-like robot driven by a CPG model to test hypotheses about the evolution from swimming to walking and the mechanisms of gait transition (Figure 4 ). Their main working hypothesis was that the salamander has kept a lamprey-like swimming circuit for its axial musculature, and that, during evolution, specialized and slower oscillatory centres have emerged to control the limbs. The CPG model could replicate gait transitions induced by electric stimulation of the mesencephalic locomotor region in a decerebrated animal [52], with the generation of a slow walking mode at low stimulation, and a faster swimming mode with traveling waves along the body at high stimulation (when the limb CPGs were saturated). The model furthermore provided an explanation of why walking gaits have systematically lower frequencies than swimming gaits in salamander, by demonstrating how the slower limb oscillators could slow down the frequencies of the whole locomotor network during walking. The concept of CPGs is now being used and tested in many types of robots, from snake to octopods [32]. In particular, quadruped cat- and dog-like robots have been useful to better understand the interactions between gait generation and balance control. For instance, Kimura and colleagues [53,54] built a series of light-weight compliant quadruped robots to investigate the interplay between CPGs, reflexes and balance control. In particular, two different options were explored: one in which sensory feedback (from tendon force, ground contact, and body orientation) acts independently of the CPG (i.e. directly on the motors) and, and one in which sensory feedback is fed through the CPG network. They found that the most stable locomotion in uneven terrains was obtained when sensory feedback is fed through the CPG network compared to when feedback does not affect CPG activity. This interplay between sensory feedback and the CPG is thus important for allowing variations of the cycle duration depending on the conditions and for allowing sensory feedback that is phase-dependent (e.g. reflexes that have different effects on limbs during swing or stance phases) similarly to what is known in the cat [55]. More recently, quadruped robots were also used to explore the mechanisms of coordination between limbs, and the respective role of neural coupling versus mechanical coupling [56]. Interestingly, it was found that direct neural coupling between limb oscillators was not necessary for generating stable gaits, something that was known from research on invertebrates, such as the stick insect [33]. Indeed stable gaits could be obtained by using decoupled oscillators that only interact through sensory feedback and mechanical coupling (as opposed to neural coupling). Different gaits could be obtained depending on the mass distribution in the robot, with more weight on the back or in front, replicating gaits observed in monkeys (centre of mass more to the back) and camels (centre of mass more to the front). Here, the robot was key to demonstrate these phenomena. Sensorimotor Coordination Vertebrates are capable of sophisticated movements that require complex sensorimotor coordination. Proper sensorimotor coordination is essential for animals and robots: any motor action needs to be guided by perception, and perception is often an active process that involves motor actions [57,58]. More than 50 years ago, Held and Hein [59] devised an ingenious experiment showing the importance of motor actions on development of the nervous system: they raised two kittens in a textured arena where the gross movement of a freely moving kitten was transmitted to a second kitten carried on a gondola preventing contact between feet and ground, so that they were both exposed to the same visual environment, but only one kitten received visual stimulation directly generated by its own motion. When tested outside the gondola, the freely moving kitten displayed normal behaviours in several visually guided tasks, whereas the other kitten failed or performed poorly. The authors concluded that correlated perception and motor actions are necessary for normal behavioural development, but could not precisely explain the mechanical cause. Suzuki, Floreano and Di Paolo [60] replicated those experiments with wheeled robots equipped with a pan-tilt camera and a neural network with Hebbian plasticity (a type of learning that involves strengthening synapses between co-activated neurons) linking the visual input to the motor commands of the camera and of the wheels. Constraints on body movements affected the development of visual receptive fields, which became responsive to sensory features that were correlated with the constrained behaviour and interfered with production of normal behaviour. This provides an explanation for the behavioural deficiencies of the suspended kitten. Another interesting example of sensorimotor coordination is offered by electric fishes, which actively emit electric pulses and which can sense objects and living beings by measuring changes in the electric fields surrounding their electrosensitive skins [61]. The black ghost knifefish, for instance, uses electric sense together with a ribbon fin that offers high manoeuvrability. Using simulations and a robotic ribbon fin prototype that can propel itself in a flow tank, MacIver and colleagues [57] provided evidence that the sensing and locomotion abilities are well matched. In particular, using optimal control theory they showed that typical swimming manoeuvres observed in the fish are very similar to those generated by the model when minimizing a cost function that approximates metabolic effort, and that they are well adjusted to the sensory abilities of the fish by increasing the quantity and resolution of sensory inflow [57]. Related work using planar or swimming robots has since successfully used electrolocation for localizing objects and avoiding obstacles [62,63]. The sense of touch is another sensory modality that has been explored with robots. A sophisticated tactile system found in mammals is one using whiskers, as found in rats and mice [64]. Whiskers allow animals to determine the shape, texture, position and motion of encountered objects. Typically whiskers are actively moved, making rhythmic sweeping movements that are continuously adjusted depending on the situation. The \u2018Whiskerbot\u2019 [58] and its successor \u2018ScratchBot\u2019 [64] explored the underlying sensorimotor mechanism using a mobile robot equipped with an articulated head and active whiskers (Figure 5 ). These projects involved replicating the morphology and mechanics of large whiskers and a neural network model of different brain areas underlying the sensorimotor coordination of the whiskers, including a model of a CPG for generating the periodic motion of the whiskers. Whiskerbot could replicate typical whisker response and orientation behaviours observed in rats in response to whisker stimulation [58]. In particular, the robot exhibited variations of amplitude of whisker oscillations, with a decrease of amplitude when there is a contact, as well as body and head movements to bring the nose of robot towards the point of contact. In related work, Schroeder and Hartmann [65] explored analogies between optical flow and the dynamical aspects of tactile sensing with whiskers. They demonstrated that, similarly to optical flow, the signals provided by whiskers when moving over an object could provide rich information about the object, such as its radial distance and its curvature. That information could be used to predict future contact points. While interesting from a neurobiological and neuroethological point of view, these projects are clearly useful for robotics to design artificial tactile systems that, like their biological counterparts, can complement vision (e.g. when in the dark) and that can serve not only to detect objects but also to recognize their motion and their properties. Navigation Some of the earliest interactions between neuroscience and robotics investigated the mechanisms of vertebrate navigation. Following the discovery of place cells in the hippocampus of rats [66], several projects have been launched to test models of vertebrate navigation using robots (for instance [67,68]). Place cells are neurons in the hippocampus that fire at a high rate when the rat is in a particular location and that are strongly dependent on visual cues [69]. Burgess and colleagues [68] have implemented a navigational system based on place cells on a small wheeled robot with a camera and a series of infrared proximity sensors. Learning rules were implemented that change the synaptic connections from in the network to gradually learn the place cell mapping when exploring the environment and that update a population vector towards specific goal/reward locations when these are visited. The robot and model correctly replicated several observations from real rats. For instance, the robot was capable of rapidly returning to goal locations, and was able to generalize when starting from new locations. Interestingly, when the environment was modified, and increased in size along one axis, the PC in the model showed the same type of adaptation as in real rats [66]. In related work, Touretzky and colleagues [67] showed that a neural model of place cells with path integration could not only explain awareness of position and orientation in space but was also sufficient for replicating results from various behavioural experiments, such as navigation in the dark and in environments that are geometrically ambiguous. Also related and going further than navigation is the ambitious concept of a \u2018brain-based device\u2019 [70] that aims at controlling a robot with a neuronal architecture composed of multiple brain areas, and to gradually endow robots with increasingly mammal-like learning abilities. Primates The behavioural repertoire of primates is vast, from bipedal locomotion to sophisticated manipulation and complex social interactions. These behaviours are controlled by a powerful nervous system, and reverse engineering of the primate brain has been put forward both in Europe and in the U.S. as one of the grand challenges for the 21st century. The behavioural neuroscience of primates requires rather reductionist methods, where the firing of single neurons, arrays of neurons, or activity of entire brain regions (as revealed by imaging studies) is correlated with well-controlled minimal behaviours. Given the many layers of information processing in the primate nervous system, it is almost impossible to obtain a clear understanding of the underlying computations without a systems level view. It was primarily in the wake of David Marr\u2019s [71] seminal work on the computational neuroscience of vision in the 1970s and 80s that a computational approach to motor control was developed [72] \u2014 indeed, Marr himself proposed an influential model of motor learning for the primate cerebellum [73\u201375]. From a physics point of view, primates are inertia-dominated systems (i.e., Reynolds number \u226b 1), and such systems have been well studied in robotics, in particular in manipulator robotics, i.e., robots with arms and legs (as opposed to mobile robots on wheels). It thus makes sense to compare theory and experiments of manipulator robotics with primate behaviour and neuroscience. Early Influence of Robotics on Primate Neuroscience In the early days of computational motor control in the 1980s, there was primarily a flow of knowledge from robotics and control theory towards an understanding of phenomena of primate behaviour and neuroscience, for instance, analysing how movement generation with muscles can control how strongly the end effector resists external force perturbations, i.e., achieve impedance control [76]. Impedance control is critical for stable force control when in contact with objects, and sophisticated impedance control can be found in human behaviour. In another line of research, optimal control approaches became popular for models of human arm movement [77], emphasizing simple organizing principles, such as the maximization of smoothness, minimum torque-change, minimum muscle command change approach, minimum task variance and others. Based on rigid-body dynamics modelling from robotics, neuroscientists discovered in the 1980s that the popular experimental paradigm examining single degree-of-freedom movements was too simplistic to reveal the complexity of motor control and planning. The two-joint arm paradigm, i.e., an arm composed of one shoulder and one elbow joint, became the prominent model of neuromotor control, which could be tested in behavioural and neurophysiological experiments in humans and monkeys. The transition from an essentially linear one degree-of-freedom movement model to a nonlinear two degree-of-freedom model sparked an interesting discussion: does the nervous system need an internal representation of the dynamics of the body for control, or can it get away without, also discussed as direct vs. indirect control [78]. Up to this time, the \u2018equilibrium point hypothesis\u2019, a popular model-free theory of biological movement control [79], postulated that the nervous system simply codes the muscle lengths that realize the target posture of a movement, while the movement to the target posture is created by the spring properties and attractor dynamics of the neuromuscular system, including spinal cord circuits. Detailed biomechanical impedance measurements of human arm movement demonstrated that equilibrium point control was an implausible model of human motor control [80], as it could not easily explain the transient characteristics of movement to the target point. Thus, model-based control became a leading hypothesis, often discussed as the internal model hypothesis [81,82]. Model-Based Control Model-based robot control, i.e., the use of internal representations to predict kinematics and/or dynamics of a control system and its environment, has been a topic in robotics for many years, but it was primarily at the end of the 1980s that some torque-controlled compliant robots became available to perform experimental evaluations \u2014 position-controlled robots do not easily allow compliant control. Models can be used to predict the dynamics and kinematics of a movement system or its environment (called \u2018forward modelling\u2019), or they can be used to compute the appropriate motor command for a desired state (called \u2018inverse modelling\u2019). An et al. [83] explored issues of model-based control in an advance torque controlled robot and laid the foundations of model-based control. Based on insights into cerebellar learning, Kawato [84] developed feedback-error learning as a model for biological learning, picked up in several robotics approaches for learning control [85,86]. Given the mathematical complexity of dynamics models of primate movement, several researchers investigated machine learning techniques to acquire such models from data. Grossberg and Kuperstein [87], for instance, developed neural networks of motor development that employed various forms of internal models. Modular control modules specialized for different tasks became of interest, based on an architecture inspired by the cerebellum, and they found verifications in human functional brain activity [88] and robotics approaches for object manipulation [89]. Atkeson et al. [90] developed an internal model learning approach based on local linearization, which successfully demonstrated internal model learning in various complex tasks with anthropomorphic robots [91\u201393] (Figure 6 ). Mehta and Schaal [94] examined the existence of an internal model for control in the task of pole-balancing (Figure 6A), and concluded from behavioural and robotic studies that there is evidence of predictive forward models in human control. The success of neuroscientific and robotic studies on learning and control with internal models has made the internal model hypothesis of primate control a largely accepted theory. Movement Planning and Imitation In both animals and robots, the question arises of how movements are planned. For a particular movement goal, there is usually an infinite number of ways to recruit a highly redundant motor system in space and time to achieve the goal, i.e., the possible combinations of muscles and the variety of trajectories to achieve a goal is countless. Nevertheless, as noted in early work on computational motor control [95,96], human and non-human primates use rather stereotypical ways to move, indicating that there are some fundamental and common principles of movement generation. As mentioned above, optimization principles were one approach to look for an organizing principle [97], and optimization is still a popular topic in computational motor control. Stochastic optimal control, i.e., optimal control that takes random effects into account, became a prominent theory of movement generation at the turn of the century, where the movement plan and the time-dependent appropriate feedback controller were computed together, which can also address impedance control [76]. While complex to compute, optimal control provided interesting explanations of experimental data [98,99] and inspired many other investigations [99,100]. The renewed success of optimal control as a neuroscientific model of primate movement also impacted the robotics literature, where many new results of full-body human motor control were derived from related optimal control theories [101\u2013103]. It should be noted that the ability to solve complex optimization problems on normal desktop computers contributed significantly to the renewed success of optimal control theories, besides several algorithmic advances. In a recent robot competition (DARPA Robotics Challenge), where human-like robots had to solve several problems of a disaster scenario, optimal control approaches to full-body motion generation were the standard rather than the exception. Another window into movement planning has been the search for general movement primitives. Movement primitives are sequences of action that accomplish a complete goal-directed behaviour [104], such as \u2018grasping a cup\u2019, \u2018walking\u2019, \u2018a tennis serve\u2019, etc. This coding results in a compact state-action representation where only a few parameters need to be adjusted for a specific goal. For instance, in reaching movements, the target state and movement duration are such parameters, or in a rhythmic movement, frequency and amplitude need to be specified [105]. Using such primitives dramatically reduces the number of parameters that need to be learned for a particular movement. The drawback is that the possible movement repertoire becomes more restricted. Many different approaches to movement primitives have been suggested in the past. For instance, planar trajectories in the end effector space have been suggested for human motor control, but some robotic experiments and theoretical analyses discounted this idea as an artefact of the human arm kinematics [106]. A similar robot analysis discounted the proposal that in human arm movement, movement velocity is coupled by a power law to movement curvature [107]. Ijspeert et al. [105] advanced the theory of dynamic movement primitives, i.e. the use of nonlinear attractor systems to generate movement plans, similar as in central pattern generators. In essence, a dynamic movement primitive prescribes the next motor command to get to the goal with some differential equations, and, due to the attractor dynamics, it can robustly realize the movement plan even when there are disturbances from the environment (such ideas are also discussed as \u2018next-state-planners\u2019, e.g., [99,108]). Dynamic movement primitives can account for data from primate motor control [109], they inspired imaging studies to look into the difference between discrete and period movement in the human brain based on the difference between point attractors and limit cycle attractors [110], and, with variations, became popular in robotic studies (Figure 7 ) [105,111,112]. Dynamic movement primitives may be an example where theories from neuroscience, behavioural sciences, and robotics managed to reciprocally influence each other and advance all the associated fields. It is also interesting to view the idea of movement primitives in the light of imitation learning [104,111] and the \u2018mirror neuron\u2019 hypothesis. The work of Rizzolatti et al. [113\u2013115] suggested that observing the movement of others involved the brain system that is also able to generate the same motor act, a hypothesis formed with the discovery of so-called mirror neurons in premotor cortex of primates. Such an idea requires that complete motor acts, i.e., movement primitives, have a specific representation in the brain, and these primitives can also be recognized in the behaviour of others. Using such a coupling between movement recognition and movement generation, particularly when combined with a particular theory of movement primitives, became a rather popular topic in computational motor control [116] and various robotic studies [117,118]. Locomotion It should be noted that robotics and neuroscience for primates has been mostly conducted in the context of reach and grasp movements [99,119]. For primate locomotion, the interaction of neuroscience and robotics is less developed. One reason may be that neuroscientific investigations of primate walking are hard to conduct, as they involve the spinal cord, which is notoriously difficult to measure from. Another reason may be that bipedal locomotion is inherently high dimensional in its actuation systems, actually involving the entire body, such that it is hard to use a reductionist experimental methodology as typical in arm movements, where mostly only two degrees of freedom are considered. One branch of neuroscience that has inspired researchers in bipedal locomotion involves control strategies of central pattern generators. Central pattern generators combine motion planning and stability, and biological realizations of bipedal locomotion have, so far, been far superior to robotic controllers. A rather complex and seminal project by Taga [120,121] modelled biped locomotion in simulation by a large network of coupled oscillators. Related projects, including robotics, can be found in [122\u2013124] (Figure 6C). This line of research often connects to the field of \u2018passive dynamic walking\u2019, which investigates how far mechanics and neuromuscular anatomy can account for stable bipedal balance control, walking, and running [125\u2013127]. Energy efficiency, minimal control, mechanical design, and stability are among the governing topics of this branch of research. Minimal robotic platforms were developed to demonstrate these principles [127]. The seminal work of Raibert [128,129] on legged hopping robots similarly demonstrated simple control principles that could achieve very robust biped (and monoped) locomotion. In contrast, humanoid robotics research employs rather complex robots that, so far, have not been easily reconciled with ideas from passive dynamic walking. Balance and locomotion control based on stability criteria derived from the centre of gravity and the zero moment point have been prominent [130]. However, one component from simpler robotic and biomechanical studies did have an interesting impact on humanoid robotics, namely the use of simplified reference dynamics from models like the inverted linear pendulum [131], which directly connects to Raibert\u2019s seminal work. These simplified models reduce the control system to the most essential parts, e.g., a centre of gravity connected by rigid rods to the floor, and, subsequently, allow easier planning and stability considerations [132\u2013134]. Simplified models have been suggested as a key to understanding the real control systems in legged locomotion [135], although the right level of simplification remains disputed. From a behavioural and biomechanical point of view, control theoretic models of biped locomotion are frequently criticized to be rather far way from known characteristics in primates. It may well be that our scientific quest for analysable models and algorithms will need to be replaced in the future by a more empirical, i.e., data and learning driven approach, as our mathematical manipulation tools of nonlinear movement systems in contact with complex environments are too limited. Conclusions Brains have co-evolved with bodies to produce tangible effects in the physical world by mediating the continuous loop between sensing and action that defines the success or failure of intelligent life. Understanding the brain thus requires understanding the behavioural effects of its circuits and processes when they interact with the environment through a physical body. In this review, we have shown that robots and robotic theories have been used in neuroscience to assess an hypothesis by translating it into an operational mechanism in a robot and observing its behaviour (validate or reject knowledge); compare alternative hypotheses against their behavioural outcome (refine knowledge); and propose a novel hypothesis that builds on embodiment or situatedness of the system (generate new knowledge). Similarly, robots that must autonomously operate in partially unknown and changing environments, as living systems do, can benefit from incorporating principles of neuroscience because it is impossible to pre-program such robots for all possible sensory-motor patterns that they will encounter during their operational life. In this review, we have shown that neuroscience can help robotics to devise novel sensing and actuation devices that simplify the control problem by increasing robustness, flexibility, and adaptability. It can further help develop simple and yet robust algorithms that effectively map sensory information into motor commands in a wide variety of environmental situations and add learning capabilities to adapt to changing situations or incorporate new sensory-motor knowledge. However, just \u2018blindly\u2019 implementing biologically inspired behaviour in a robot may not provide any insights into biology nor novel ideas for robotics. Similarly, applying theoretical and algorithmic knowledge from robotics to biological modelling may not have any valid application to understanding brains. Most successful projects had prudent iterations between neuroscience and robotics until the right questions were asked, good methods were devised, and finally compelling results could be obtained. David Marr\u2019s [71] strategic thinking in terms of theory, algorithms and implementation may remain a useful guiding principle: theory could be shared between neuroscience and robotics, algorithms may be similar, while implementations are usually quite different due to different hardware. Richard Feynman\u2019s quote of \u201cWhat I cannot build, I cannot understand.\u201d is at the essence of the interaction of neuroscience and robotics, as, in the end, biological and robotic systems have to deal with largely similar physics and similar environments. Acknowledgments This work was supported in parts by the Swiss National Center of Competence in Research (NCCR) Robotics, the Max-Planck-Society, and the U.S. National Science Foundation. References 1 W.J. Freeman Biographical Essay on W. Grey Walter 2001 Encyclopedia of Cognitive Science 2 W.G. Walter An imitation of life Sci. Am. 182 1950 42 45 3 V. Braitenberg Vehicles: Experiments in Synthetic Psychology 1986 MIT press 4 H.J. Chiel R.D. Beer The brain has a body: adaptive behavior emerges from interactions of nervous system, body and environment Trends Neurosci. 20 1997 553 557 5 Cliff, D. (1991). Computational neuroethology: a provisional manifesto. In J.A. Meyer and S.W. Wilson (eds) from Animals to Animats 3: Proceeding of the First International Conference on the simulation of Adaptive Behaviour. pp. 29\u201339. 6 K. Nishikawa A.A. Biewener P. Aerts A.N. Ahn H.J. Chiel M.A. Daley T.L. Daniel R.J. Full M.E. Hale T.L. Hedrick Neuromechanics: an integrative approach for understanding motor control Integr. Comparative Biol. 47 2007 16 54 7 B. Webb Robots in invertebrate neuroscience Nature 417 2002 359 363 8 B. Webb T. Scutt A simple latency-dependent spiking-neuron model of cricket phonotaxis Biol. Cybern. 82 2000 247 269 9 F.W. Grasso T.R. Consi D.C. Mountain J. Atema Biomimetic robot lobster performs chemo-orientation in turbulence using a pair of spatially separated sensors: Progress and challenges Robotics Autonomous Systems 30 2000 115 131 10 P. Pyk S.B. i Badia U. Bernardet P. Kn\u00fcsel M. Carlsson J. Gu E. Chanie B.S. Hansson T.C. Pearce P.F. Verschure An artificial moth: Chemical source localization using a robot based neuronal model of moth optomotor anemotactic search Auton. Robot 20 2006 197 213 11 D. Floreano J.-C. Zufferey M.V. Srinivasan C. Ellington Flying Insects and Robots 2009 Springer 12 G.A. Horridge H.C. Longuet-Higgins What can engineers learn from insect vision?[and Discussion] Philos. Trans. R. Soc. Lond. B. Biol. Sci. 337 1992 271 282 13 A. Borst J. Haag Neural networks in the cockpit of the fly J. Comp. Physiol. A 188 2002 419 437 14 J.J. Koenderink Optic flow Vision Res. 26 1986 161 179 15 H. Wagner Flight performance and visual control of flight of the free-flying housefly (Musca domestica L.) I. Organization of the flight motor Philos. Trans. R. Soc. Lond. B. Biol. Sci. 312 1986 527 551 16 N. Franceschini J.-M. Pichon C. Blanes J.M. Brady From insect vision to robot vision [and discussion] Philos. Trans. R. Soc. Lond. B. Biol. Sci. 337 1992 283 294 17 M.V. Srinivasan Honeybees as a model for the study of visually guided flight, navigation, and biologically inspired robotics Physiol. Rev. 91 2011 389 411 18 N. Franceschini F. Ruffier J. Serres A bio-inspired flying robot sheds light on insect piloting abilities Curr. Biol. 17 2007 329 335 19 J.-C. Zufferey A. Klaptocz A. Beyeler J.-D. Nicoud D. Floreano A 10-gram vision-based flying robot Advanced Robotics 21 2007 1671 1684 20 A. Beyeler J.-C. Zufferey D. Floreano Vision-based control of near-obstacle flight Auton. Robot 27 2009 201 219 21 J.S. Humbert J.K. Conroy C.W. Neely G. Barrows Wide-field integration methods for visuomotor control Flying Insects and Robots 2010 Springer 63 71 22 Y.M. Song Y. Xie V. Malyarchuk J. Xiao I. Jung K.-J. Choi Z. Liu H. Park C. Lu R.-H. Kim Digital cameras with designs inspired by the arthropod eye Nature 497 2013 95 99 23 D. Floreano R. Pericet-Camara S. Viollet F. Ruffier A. Br\u00fcckner R. Leitel W. Buss M. Menouni F. Expert R. Juston Miniature curved artificial compound eyes Proc. Natl. Acad. Sci. USA 110 2013 9267 9272 24 S.B. Fuller M. Karpelson A. Censi K.Y. Ma R.J. Wood Controlling free flight of a robotic fly using an onboard vision sensor inspired by insect ocelli J. R. Soc. Interface 11 2014 20140281 25 K.A. Daltorio A.S. Boxerbaum A.D. Horchler K.M. Shaw H.J. Chiel R.D. Quinn Efficient worm-like locomotion: slip and control of soft-bodied peristaltic robots Bioinspiration Biomimetics 8 2013 035003 26 Kovac, M., Fuchs, M., Guignard, A., Zufferey, J.-C., and Floreano, D. (2008). A miniature 7g jumping robot. IEEE International Conference on Robotics and Automation. pp. 373\u2013378. 27 K.Y. Ma P. Chirarattananon S.B. Fuller R.J. Wood Controlled flight of a biologically inspired, insect-scale robot Science 340 2013 603 607 28 D.L. Hu B. Chan J.W. Bush The hydrodynamics of water strider locomotion Nature 424 2003 663 666 29 Y.S. Song M. Sitti Surface-tension-driven biologically inspired water strider robots: Theory and experiments Robotics IEEE Trans. 23 2007 578 589 30 E.J. Izquierdo R.D. Beer Connecting a connectome to behavior: an ensemble of neuroanatomical models of C. elegans klinotaxis PLoS Comput. Biol. 9 2013 e1002890 31 R.D. Beer H.J. Chiel R.D. Quinn K.S. Espenschied P. Larsson A distributed neural network architecture for hexapod robot locomotion Neural. Comput. 4 1992 356 365 32 A.J. Ijspeert Central pattern generators for locomotion control in animals and robots: a review Neural. Netw. 21 2008 642 653 33 H. Cruse What mechanisms coordinate leg movement in walking arthropods? Trends Neurosci. 13 1990 15 21 34 Nelson, G.M., Quinn, R.D., Bachmann, R.J., Flannigan, W.C., Ritzmann, R.E., and Watson, J.T. (1997). Design and simulation of a cockroach-like hexapod robot. In Proc. of the 1997 Intl. Conf. on Robotics and Automation. pp. 1106\u20131111. 35 Kingsley, D.A., Quinn, R.D., and Ritzmann, R.E. (2006). A cockroach inspired robot with artificial muscles. In Intelligent Robots and Systems 2006 IEEE/RSJ International Conference. pp. 1837\u20131842. 36 J. Ayers J. Witting Biomimetic approaches to the control of underwater walking machines Phil. Trans. R. Soc. A Mathematical Phys. Eng. Sci. 365 2007 273 295 37 J.C. Spagna D.I. Goldman P.-C. Lin D.E. Koditschek R.J. Full Distributed mechanical feedback in arthropods and robots simplifies control of rapid running on challenging terrain Bioinspiration Biomimetics 2 2007 9 38 J. Zeil N. Boeddeker W. St\u00fcrzl Visual homing in insects and robots Flying Insects and Robots 2010 Springer 87 100 39 B.A. Cartwright T.S. Collett Landmark learning in bees J. Comp. Physiol. 151 1983 521 543 40 A.M. Anderson A model for landmark learning in the honey-bee J. Comp. Physiol. A 114 1977 335 355 41 D. Lambrinos R. M\u00f6ller T. Labhart R. Pfeifer R. Wehner A mobile robot employing insect strategies for navigation Robot. Auton. Sys. 30 2000 39 64 42 R. M\u00f6ller Insect visual homing strategies in a robot with analog processing Biol. Cybern. 83 2000 231 243 43 R. M\u00f6ller Local visual homing by warping of two-dimensional images Robot. Auton. Sys. 57 2009 87 101 44 M.O. Franz B. Sch\u00f6lkopf H.A. Mallot H.H. B\u00fclthoff Learning view graphs for robot navigation Autonomous Robots 5 1998 111 125 45 J. Zeil M.I. Hofmann J.S. Chahl Catchment areas of panoramic snapshots in outdoor scenes JOSA A 20 2003 450 469 46 S. Grillner B. Robertson M. Stephenson-Jones The evolutionary origin of the vertebrate basal ganglia and its role in action selection J. Physiol. 591 2013 5425 5431 47 S. Grillner T. Deliagina A. Manira El R.H. Hill G.N. Orlovsky P. Wall\u00e9n O. Ekeberg A. Lansner Neural networks that co-ordinate locomotion and body orientation in lamprey Trends Neurosci. 18 1995 270 279 48 C. Wilbur W. Vorus Y. Cao S.N. Currie A Lamprey-based Undulatory Vehicle 2002 MIT Press Cambridge, MA 49 L. Manfredi T. Assaf S. Mintchev S. Marrazza L. Capantini S. Orofino L. Ascari S. Grillner P. Wall\u00e9n \u00d6. Ekeberg A bioinspired autonomous swimming robot as a tool for studying goal-directed locomotion Biol. Cybern. 107 2013 513 527 50 \u00d6. Ekeberg A combined neuronal and mechanical model of fish swimming Biol. Cybern. 69 1993 363 374 51 A.J. Ijspeert A. Crespi D. Ryczko J.M. Cabelguen From swimming to walking with a salamander robot driven by a spinal cord model Science 315 2007 1416 1420 52 J.-M. Cabelguen C. Bourcier-Lucas R. Dubuc Bimodal locomotion elicited by electrical stimulation of the midbrain in the salamander Notophthalmus viridescens J. Neurosci. 23 2003 2434 2439 53 H. Kimura Y. Fukuoka K. Konaga Adaptive dynamic walking of a quadruped robot using a neural system model Advanced Robotics 15 2001 859 878 54 H. Kimura Y. Fukuoka A.H. Cohen Adaptive dynamic walking of a quadruped robot on natural ground based on biological concepts Int. J. Robot Res. 26 2007 475 490 55 K.G. Pearson Generating the walking gait: role of sensory feedback Prog. Brain Res. 143 2004 123 129 56 D. Owaki T. Kano K. Nagasawa A. Tero A. Ishiguro Simple robot suggests physical interlimb communication is essential for quadruped walking J. R. Soc. Interface 10 2013 20120669 57 M.A. MacIver E. Fontaine J.W. Burdick Designing future underwater vehicles: principles and mechanisms of the weakly electric fish IEEE J. Oceanic Eng. 29 2004 651 659 58 M.J. Pearson A.G. Pipe C. Melhuish B. Mitchinson T.J. Prescott Whiskerbot: a robotic active touch system modeled on the rat whisker sensory system Adaptive Behavior 15 2007 223 240 59 R. Held A. Hein Movement-produced stimulation in the development of visually guided behavior J. Comp. Physiol. Psychol. 56 1963 872 60 M. Suzuki D. Floreano E. Di Paolo The contribution of active body movement to visual development in evolutionary robots Neural Networks 2005 656 665 61 I.D. Neveln Y. Bai J.B. Snyder J.R. Solberg O.M. Curet K.M. Lynch M.A. MacIver Biomimetic and bio-inspired robotics in electric fish research J. Exp. Biol. 216 2013 2501 2514 62 J.R. Solberg K.M. Lynch M.A. MacIver Active electrolocation for underwater target localization Inter. J. Robot. Res. 27 2008 529 548 63 F. Boyer P.B. Gossiaux B. Jawad V. Lebastard M. Porez Model for a sensor inspired by electric fish IEEE Trans. Robotics 28 2012 492 505 64 T.J. Prescot M.J. Pearson B. Mitchinson Whisking with robots IEEE Robotics and Automation Magazine 2009 September, 42\u201350 65 C.L. Schroeder M.J. Hartmann Sensory prediction on a whiskered robot: a tactile analogy to \u201coptical flow\u201d Front. Neurorobotics 6 2012 66 J. O'Keefe N. Burgess Geometric determinants of the place fields of hippocampal neurons Nature 381 1996 425 428 67 D.S. Touretzky H.S. Wan A.D. Redish Neural representation of space in rats and robots Computational Intelligence Imitating Life 1994 57 68 68 N. Burgess J.G. Donnett K.J. Jeffery O. John Robotic and neuronal simulation of the hippocampus and rat navigation Philos. Trans. R. Soc. Lond. B. Biol. Sci. 352 1997 1535 1543 69 J. O'Keefe A review of the hippocampal place cells Prog. Neurobiol. 13 1979 419 439 70 J.G. Fleischer J.A. Gally G.M. Edelman J.L. Krichmar Retrospective and prospective responses arising in a modeled hippocampus during maze navigation by a brain-based device Proc. Natl. Acad. Sci. USA 104 2007 3556 3561 71 D. Marr Vision - A Computational Investigation into the Human Representation and Processing of Visual Information 1982 W.H. Freeman and Company San Francisco, CA 72 E.C. Hildreth J.M. Hollerbach The Computational Approach to Vision and Motor Control 1985 A.I. Memo 846, Massachusetts Intitute of Technology 73 D. Marr A theory of cerebellar cortex J. Physiol. 202 1968 437 470 74 J.S. Albus A new approach to manipulator control: The Cerebellar Model Articulation Controller (CMAC) ASME J. Dynamic Systems Measurements Control 97 1975 228 233 75 M. Ito Cerebellar control of the vestibulo-ocular reflex - Around the flocculus hypothesis Annu. Rev. Neurosci. 1982 275 296 76 N. Hogan Adaptive control of mechanical impedance by coactivation of antagonist muscles IEEE Trans. Automatic Control 29 1984 681 690 77 T. Flash N. Hogan The coordination of arm movements: An experimentally confirmed mathematical model J. Neurosci. 5 1985 1688 1703 78 J.J.E. Slotine W. Li Applied Nonlinear Control 1991 Prentice Hall Englewood Cliffs, NJ 79 M.L. Latash Control of Human Movement 1993 Human Kinetics Publisher Champaign, IL 80 H. Gomi M. Kawato Equilibrium-point control hypothesis examined by measured arm stiffness during multijoint movement Science 272 1996 117 220 81 D.M. Wolpert R.C. Miall M. Kawato Internal models in the cerebellum Trends Cogn. Sci. 2 1998 338 347 82 M. Kawato Internal models for motor control and trajectory planning Curr. Opin. Neurobiol. 9 1999 718 727 83 C.H. An C.G. Atkeson J.M. Hollerbach Model-Based Control of a Robot Manipulator 1987 MIT Press (MA) 84 M. Kawato Feedback-error learning neural network for supervised motor learning Advances in Neural Computation 1990 Elsevier North-Holland 365 372 85 T. Shibata S. Schaal Biomimetic gaze stabilization based on feedback-error-learning with nonparametric regression networks Neural Netw. 14 2001 201 216 86 J. Nakanishi S. Schaal Feedback error learning and nonlinear adaptive control Neural Networks 17 2004 1453 1465 87 S. Grossberg M. Kuperstein Neural Dynamics of Adaptive Sensory-motor Control 1989 Cambridge Univ. Press 88 H. Imamizu T. Kuroda S. Miyauchi T. Yoshioka M. Kawato Modular organization of internal models of tools in the human cerebellum Proc. Natl. Acad. Sci. USA 100 2003 5461 5466 89 H. Gomi M. Kawato Recognition of manipulated objects by motor learning with modular architecture networks Neural Networks 6 1993 485 497 90 C.G. Atkeson A.W. Moore S. Schaal Locally weighted learning for control Artif. Intell. Rev. 11 1997 75 113 91 S. Schaal C.G. Atkeson Robot juggling: implementation of memory-based learning IEEE Control Systems Magazine 14 1994 57 71 92 S. Schaal C.G. Atkeson Constructive incremental learning from only local information Neural Comput. 10 1998 2047 2084 93 S. Vijayakumar A. D'Souza S. Schaal Incremental online learning in high dimensions Neural Comput. 17 2005 2602 2634 94 B. Mehta S. Schaal Forward models in visuomotor control J. Neurophysiol. 88 2002 942 953 95 P. Morasso Spatial control of arm movements Exp. Brain Res. 42 1981 223 227 96 P. Morasso Three dimensional arm trajectories Biol Cybern. 48 1983 187 194 97 R.B. Stein M.N. Oguszt\u00f6reli C. Capaday What is optimized in muscular movements? N.L. Jones N. McCartney A.J. McComas Human Muscle Power 1986 Human Kinetics Publisher Champaign, Illinois 131 150 98 E. Todorov Optimality principles in sensorimotor control Nat. Neurosci. 7 2004 907 915 99 R. Shadmehr S.P. Wise The Computational Neurobiology of Reaching and Pointing: a Foundation for Motor Learning 2005 MIT Press Cambridge, Mass. 100 S.H. Scott Optimal feedback control and the neural basis of volitional motor control Nature 5 2004 532 546 101 E. Todorov Efficient computation of optimal actions Proc. Natl. Acad. Sci. USA 106 2009 11478 11483 102 E.A. Theodorou J. Buchli S. Schaal A generalized path integral control approach to reinforcement learning J. Mach. Learn Res. 11 2010 3137 3181 103 F. Stulp J. Buchli A. Ellmer M. Mistry E. Theodorou S. Schaal Model-free reinforcement learning of impedance control in stochastic environments IEEE Trans. Autonomous Mental Development 2012 1 104 S. Schaal Is imitation learning the route to humanoid robots? Trends Cogn. Sci. 3 1999 233 242 105 A.J. Ijspeert J. Nakanishi H. Hoffmann P. Pastor S. Schaal Dynamical movement primitives: learning attractor models for motor behaviors Neural. Comput. 25 2013 328 373 106 D. Sternad D. Schaal Segmentation of endpoint trajectories does not imply segmented control Exp. Brain Res. 124 1999 118 136 107 S. Schaal D. Sternad Origins and violations of the 2/3 power law in rhythmic 3D movements Exp. Brain Res. 136 2001 60 72 108 D. Bullock S. Grossberg Neural dynamics of planned arm movements: Emergent invariants and speed-accuracy properties during trajectory formation Psychol. Rev. 95 1988 49 90 109 S. Schaal P. Mohajerian A. Ijspeert Dynamics systems vs. optimal control\u2013a unifying view Prog. Brain Res. 165 2007 425 445 110 S. Schaal D. Sternad R. Osu M. Kawato Rhythmic movement is not discrete Nat. Neurosci. 7 2004 1137 1144 111 A. Billard S. Calinon R. Dillmann S. Schaal Robot programming by demonstration B. Siciliano O. Khatib Handbook of Robotics 2008 MIT Press 112 P. Pastor M. Kalakrishnan F. Meier F. Stulp J. Buchli E. Theodorou S. Schaal From dynamic movement primitives to associative skill memories Robot. Auton. Sys. 61 2013 351 361 113 G. Rizzolatti L. Fadiga V. Gallese L. Fogassi Premotor cortex and the recognition of motor actions Cogn. Brain Res. 3 1996 131 141 114 G. Rizzolatti M.A. Arbib Language within our grasp Trends Neurosci. 21 1998 188 194 115 Arbib, M.A. (2010). Action to Language via the Mirror Neuron System M. Arbib, ed. (Cambridge University Press). 116 E. Oztop M. Kawato M. Arbib Mirror neurons and imitation: A computationally guided review Neural Netw. 19 2006 254 271 117 Y. Demiris B. Khadhouri Hierarchical attentive multiple models for execution and recognition of actions Robot. Auton. Sys. 54 2006 361 369 118 A. Billard S. Schaal Special issue on the brain mechanisms of imitation learning Neural. Networks 19 2006 251 253 119 E. Burdet D.W. Franklin T.E. Milner Human Robotics 2013 MIT Press 120 G. Taga Y. Yamaguchi H. Shimizu Self-organized control of bipedal locomotion by neural oscillators in unpredictable environment Biol. Cybern. 65 1991 147 159 121 G.G. Taga A model of the neuro-musculo-skeletal system for anticipatory adjustment of human locomotion during obstacle avoidance Biol. Cybern. 78 1998 9 17 122 G. Endo J. Morimoto T. Matsubara J. Nakanish G. Cheng Learning CPG-based biped locomotion with a policy gradient method: Application to a humanoid robot Int. J. Robot. Res. 27 2008 213 228 123 T. Matsubara J. Morimoto J. Nakanishi M.A. Sato K. Doya Learning CPG-based biped locomotion with a policy gradient method Robot. Auton. Sys. 54 2006 911 920 124 S. Aoi K. Tsuchiya Locomotion control of a biped robot using nonlinear oscillators Auton. Robot. 19 2005 219 232 125 T. Geng B. Porr F. Worgotter A reflexive neural network for dynamic biped walking control Neural Comput. 18 2006 1156 1196 126 T. Geng B. Porr F. Worgotter Fast biped walking with a sensor-driven neuronal controller and real- time online learning Int. J. Robot Res. 25 2006 243 259 127 S. Collins A. Ruina R. Tedrake M. Wisse Efficient bipedal robots based on passive-dynamic walkers Science 307 2005 1082 1085 128 J.K. Hodgins M.H. Raibert Biped gymnastics Int. J. Robot Res. 1989 249 252 129 M. Raibert Legged Robots that Balance 1986 MIT Press Cambridge, MA 130 S. Kajita B. Espiau Legged robots B. Sicilian O. Khatib Handbook of Robotics 2008 Springer 131 S. Kajita B. Espiau Legged Robots Handbook of robotics 2008 Springer 132 Pratt, J., Carff, J., Drakunov, S., and Goswami, A. (2006). Capture point: A step toward humanoid push recovery. In 2006 6th IEEE-RAS International Conference on Humanoid Robots. pp. 1976\u20131983. 133 T. Koolen T. de Boer J. Rebula A. Goswami J. Pratt Capturability-based analysis and control of legged locomotion, Part 1: Theory and application to three simple gait models Inter. J. Robot. Res. 31 2012 1094 1113 134 Yun, S.-K., and Goswami, A. (2011). Momentum-based reactive stepping controller on level and non-level ground for humanoid robot push recovery. IROS. pp. 3943\u20133950. 135 R.J.R. Full D.E.D. Koditschek Templates and anchors: neuromechanical hypotheses of legged locomotion on land J. Exp. Biol. 202 1999 3325 3332", "scopus-id": "84908152259", "pubmed-id": "25247370", "coredata": {"eid": "1-s2.0-S096098221400921X", "dc:description": "In the attempt to build adaptive and intelligent machines, roboticists have looked at neuroscience for more than half a century as a source of inspiration for perception and control. More recently, neuroscientists have resorted to robots for testing hypotheses and validating models of biological nervous systems. Here, we give an overview of the work at the intersection of robotics and neuroscience and highlight the most promising approaches and areas where interactions between the two fields have generated significant new insights. We articulate the work in three sections, invertebrate, vertebrate and primate neuroscience. We argue that robots generate valuable insight into the function of nervous systems, which is intimately linked to behaviour and embodiment, and that brain-inspired algorithms and devices give robots life-like capabilities.", "openArchiveArticle": "true", "prism:coverDate": "2014-09-22", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S096098221400921X", "dc:creator": [{"@_fa": "true", "$": "Floreano, Dario"}, {"@_fa": "true", "$": "Ijspeert, Auke Jan"}, {"@_fa": "true", "$": "Schaal, Stefan"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S096098221400921X"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S096098221400921X"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0960-9822(14)00921-X", "prism:volume": "24", "prism:publisher": "Elsevier Ltd.", "dc:title": "Robotics and Neuroscience", "prism:copyright": "Copyright \u00a9 2014 Elsevier Ltd. All rights reserved.", "openaccess": "1", "prism:issn": "09609822", "prism:issueIdentifier": "18", "openaccessArticle": "true", "prism:publicationName": "Current Biology", "prism:number": "18", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "R910-R920", "prism:endingPage": "R920", "pubType": "rev", "prism:coverDisplayDate": "22 September 2014", "prism:doi": "10.1016/j.cub.2014.07.058", "prism:startingPage": "R910", "dc:identifier": "doi:10.1016/j.cub.2014.07.058", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "163", "@width": "119", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "22187", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "135", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "19073", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "138", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "22435", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "135", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "25222", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "108", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "23160", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "113", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "25635", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "90", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "19716", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "516", "@width": "376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "61148", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "232", "@width": "376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "21854", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "319", "@width": "505", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "50799", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "311", "@width": "505", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62867", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "572", "@width": "376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "83058", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "261", "@width": "506", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "46192", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "683", "@width": "375", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "73550", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2288", "@width": "1666", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "356584", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1028", "@width": "1666", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "144323", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1413", "@width": "2238", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "264828", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1379", "@width": "2237", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "426133", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2533", "@width": "1666", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "742861", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1155", "@width": "2241", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "275653", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3023", "@width": "1660", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S096098221400921X-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "457102", "@ref": "gr7", "@mimetype": "image/jpeg"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84908152259"}}